# src/ui/app_streamlit_webrtc.py
# -*- coding: utf-8 -*-
import os, io, json, time, wave, base64, requests
import numpy as np
import streamlit as st
from dotenv import load_dotenv
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase

load_dotenv()
st.set_page_config(page_title="MinBiz Voice Agent (WebRTC)", page_icon="ğŸ™ï¸", layout="centered")

# ====== åç«¯é…ç½® ======
API_BASE = os.getenv("VOICE_AGENT_API", "http://127.0.0.1:8000")
API_KEY  = os.getenv("MINBIZ_API_KEY", "")
HEADERS  = {"X-API-Key": API_KEY} if API_KEY else {}
ICE_JSON = os.getenv("WEBRTC_ICE_JSON", "").strip()

RTC_CONFIG = json.loads(ICE_JSON) if ICE_JSON else {
    "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
}

with st.expander("Connection diagnostics", expanded=False):
    st.json({"API_BASE": API_BASE, "API_KEY_present": bool(API_KEY), "RTC_CONFIG": RTC_CONFIG})

st.title("ğŸ™ï¸ MinBiz Voice Agent (WebRTC)")

# ====== æ–‡æœ¬é—®ç­”ï¼ˆå¯é€‰ï¼‰ ======
st.subheader("ğŸ’¬ Ask by text")
col1, col2, col3 = st.columns(3)
with col1:
    style = st.selectbox("Style", ["story", "concise", "coach"], index=0)
with col2:
    lang  = st.selectbox("Language", ["auto", "en", "zh"], index=0)
with col3:
    bilingual = st.toggle("Bilingual (ä¸­è‹±åŒè¯­)", value=False)
text_q = st.text_area("Your question", value="", height=80, placeholder="Type here and click Ask")
if st.button("Ask"):
    try:
        r = requests.post(
            f"{API_BASE}/ask-text-v2",
            headers=HEADERS,
            data={"q": text_q, "style": style, "lang": lang, "bilingual": str(bilingual).lower()},
            timeout=180
        )
        r.raise_for_status()
        out = r.json()
        st.success("Answer")
        st.write(out.get("answer") or out)

        # å¦‚æœåç«¯ä¹Ÿè¿”å›äº†TTSåˆ†æ®µï¼Œé¡ºä¾¿æ’­ä¸€ä¸‹
        segs = out.get("audio_segments_b64") or []
        if segs:
            fmt = "audio/mp3" if out.get("audio_format") == "mp3" else "audio/wav"
            for i, b64 in enumerate(segs, 1):
                st.audio(io.BytesIO(base64.b64decode(b64)), format=fmt)
    except Exception as e:
        st.error(f"Text ask failed: {e}")

st.divider()

# ====== è¯­éŸ³é—®ç­”ï¼ˆWebRTC å½•éŸ³ï¼‰ ======
st.subheader("ğŸ™ï¸ Browser Mic (WebRTC)")
st.caption("ç‚¹å‡» Start å»ºç«‹è¿æ¥ï¼Œè¯´è¯åç‚¹å‡» Stop & Submit æäº¤ã€‚è‹¥æ— æ³•è¿æ¥ï¼Œå¤šåŠéœ€è¦é…ç½® TURN æœåŠ¡å™¨ã€‚")

if "webrtc_pcm" not in st.session_state:
    st.session_state["webrtc_pcm"] = []

class AudioCollector(AudioProcessorBase):
    """æŠŠæ¯ä¸€å¸§éŸ³é¢‘è½¬æˆ int16 å•å£°é“ PCM ç¼“å†²åˆ° session_state"""
    def __init__(self) -> None:
        # åˆå§‹åŒ–ç¼“å†²
        if "webrtc_pcm" not in st.session_state:
            st.session_state["webrtc_pcm"] = []

    def recv(self, frame):
        pcm = frame.to_ndarray()  # shape: (channels, samples)
        if pcm.ndim == 2:
            pcm = pcm[0]
        pcm = pcm.astype(np.int16)
        st.session_state["webrtc_pcm"].append(pcm.tobytes())
        return frame  # å¿…é¡»å›ä¼ 

ctx = webrtc_streamer(
    key="minbiz-voice",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=1024,
    media_stream_constraints={"audio": True, "video": False},
    rtc_configuration=RTC_CONFIG,
    audio_processor_factory=AudioCollector,
)

# å‚æ•°
c1, c2, c3 = st.columns(3)
with c1:
    v_style = st.selectbox("Voice style", ["story", "concise", "coach"], index=0)
with c2:
    v_lang  = st.selectbox("Voice lang", ["auto", "en", "zh"], index=0)
with c3:
    v_bilingual = st.toggle("Voice bilingual", value=False)

def pcm_chunks_to_wav(chunks: list[bytes], sample_rate=16000) -> bytes:
    pcm = b"".join(chunks)
    bio = io.BytesIO()
    with wave.open(bio, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)         # int16
        wf.setframerate(sample_rate)
        wf.writeframes(pcm)
    return bio.getvalue()

# æäº¤æŒ‰é’®
if st.button("Stop & Submit", type="primary"):
    try:
        chunks = st.session_state.get("webrtc_pcm", [])
        if not chunks:
            st.warning("è¿˜æ²¡æœ‰é‡‡é›†åˆ°éŸ³é¢‘ã€‚è¯·å…ˆ Start è¿æ¥æˆåŠŸåå†è¯´è¯ï¼Œç„¶åå†ç‚¹ Submitã€‚")
        else:
            wav_bytes = pcm_chunks_to_wav(chunks, sample_rate=16000)
            files = {"audio": ("voice.wav", wav_bytes, "audio/wav")}
            data  = {"style": v_style, "lang": v_lang, "bilingual": str(v_bilingual).lower()}
            r = requests.post(f"{API_BASE}/ask-voice-v2", headers=HEADERS, files=files, data=data, timeout=180)
            r.raise_for_status()
            out = r.json()

            st.success("ASR Transcript")
            st.write(out.get("question", ""))

            st.success("Answer")
            st.write(out.get("answer", ""))

            segs = out.get("audio_segments_b64") or []
            if segs:
                fmt = "audio/mp3" if out.get("audio_format") == "mp3" else "audio/wav"
                for i, b64 in enumerate(segs, 1):
                    st.audio(io.BytesIO(base64.b64decode(b64)), format=fmt)

            # æ¸…ç©ºç¼“å†²ï¼Œé¿å…ä¸‹æ¬¡æŠŠä¸Šä¸€æ¬¡çš„å†…å®¹æ··è¿›å»
            st.session_state["webrtc_pcm"] = []
    except Exception as e:
        st.error(f"Voice submit failed: {e}")
